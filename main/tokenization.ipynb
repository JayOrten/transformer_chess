{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/jayor/.cache/huggingface/datasets/royal42___parquet/royal42--lichess_elite_games-24250dad91f3120d/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.45it/s]\n"
     ]
    }
   ],
   "source": [
    "raw = load_dataset(\"royal42/lichess_elite_games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'e4 d5 exd5 Qxd5 Nc3 Qa5 d4 c6 Nf3 Nf6 Bd2 Qc7 Bc4 Bg4 O-O e6 h3 Bh5 Qe2 Be7 g4 Bg6 Ne5 Nbd7 Bf4 Nxe5 Bxe5 Qb6 Bb3 Rd8 a4 Rxd4 a5 Qc5 Bxd4 Qxd4 Ra4 Qc5 Rd1 h5 Qc4 hxg4 Qxc5 Bxc5 Rc4 b6 hxg4 Rh4 axb6 axb6 Ba4 Rxg4+ Rxg4 Nxg4 Bxc6+ Ke7 Rd7+ Kf6 Rd2 Ne5 Be4 Bh5 Na4 Nc4 Rd7 Nxb2 Nxb2 Ke5 Bc6 g5 Nd3+ Kf5 Nxc5 bxc5 Rc7 Be2 Bg2 c4 Bf1 Bxf1 Kxf1'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['train'][3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    dataset = raw[\"train\"]\n",
    "    for start_idx in range(0, len(dataset), 1000):\n",
    "        samples = dataset[start_idx : start_idx + 1000]\n",
    "        yield samples[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = get_training_corpus()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train new tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e',\n",
       " '4',\n",
       " 'Ġd',\n",
       " '5',\n",
       " 'Ġexd',\n",
       " '5',\n",
       " 'ĠQxd',\n",
       " '5',\n",
       " 'ĠNc',\n",
       " '3',\n",
       " 'ĠQa',\n",
       " '5',\n",
       " 'Ġd',\n",
       " '4',\n",
       " 'Ġc',\n",
       " '6',\n",
       " 'ĠNf',\n",
       " '3',\n",
       " 'ĠNf',\n",
       " '6',\n",
       " 'ĠBd',\n",
       " '2',\n",
       " 'ĠQc',\n",
       " '7']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = '''e4 d5 exd5 Qxd5 Nc3 Qa5 d4 c6 Nf3 Nf6 Bd2 Qc7'''\n",
    "\n",
    "tokens = tokenizer.tokenize(example)\n",
    "tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/tokenizations/chess-tokenizer\\\\tokenizer_config.json',\n",
       " '../data/tokenizations/chess-tokenizer\\\\special_tokens_map.json',\n",
       " '../data/tokenizations/chess-tokenizer\\\\vocab.json',\n",
       " '../data/tokenizations/chess-tokenizer\\\\merges.txt',\n",
       " '../data/tokenizations/chess-tokenizer\\\\added_tokens.json',\n",
       " '../data/tokenizations/chess-tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"../data/tokenizations/chess-tokenizer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
